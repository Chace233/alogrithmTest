package webcollector;


import cn.edu.hfut.dmic.contentextractor.ContentExtractor;
import cn.edu.hfut.dmic.contentextractor.News;
import cn.edu.hfut.dmic.webcollector.model.CrawlDatums;
import cn.edu.hfut.dmic.webcollector.model.Page;
import cn.edu.hfut.dmic.webcollector.plugin.berkeley.BreadthCrawler;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class KrCrawler extends BreadthCrawler {
    public KrCrawler(String crawlPath, boolean autoParse) {
	    super(crawlPath, autoParse);
	    this.addSeed("http://36kr.com");
	    this.addRegex("http://36kr.com/p/.*");
	    this.addRegex("-.*\\.(jpg|png|gif).*");
	    this.addRegex("-.*#.*");
    }

    @Override
    public void visit(Page page, CrawlDatums next) {
    	String url = page.getUrl();
    	System.out.println("URL: "+url);
	    if (page.matchUrl("http://36kr.com/p/.*")) {
	        String  title = page.select("h1").text();
	        System.out.println("title:\n" + title);
	        String content = page.select("section").text();
	        System.out.println("content: "+ content);
		}
    }

    public static void main(String[] args) throws Exception {
    	KrCrawler crawler = new KrCrawler("crawl", true);
	    crawler.setThreads(50);
	    crawler.setTopN(1);
	    crawler.start(4);
    }

}

