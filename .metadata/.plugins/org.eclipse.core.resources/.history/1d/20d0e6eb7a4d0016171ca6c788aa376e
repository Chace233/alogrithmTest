package webcollector;

import cn.edu.hfut.dmic.webcollector.model.CrawlDatums;
import cn.edu.hfut.dmic.webcollector.model.Page;
import cn.edu.hfut.dmic.webcollector.plugin.berkeley.BreadthCrawler;

public class techcrunchCrawler extends BreadthCrawler{

	public techcrunchCrawler(String crawlPath, boolean autoParse) {
		super(crawlPath, autoParse);
	}

	@Override
	public void visit(Page page, CrawlDatums next) {
		
		
	}
	
	public static void main(String[] args){
		techcrunchCrawler crawler = new techcrunchCrawler("crawl",true);
		crawler.addSeed("https://techcrunch.com/");
		crawler.addRegex("https://techcrunch.com/.*");
	    this.addRegex("-.*\\.(jpg|png|gif).*");
	    this.addRegex("-.*#.*");
	}

}
