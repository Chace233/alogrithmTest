package webcollector;

import cn.edu.hfut.dmic.webcollector.model.CrawlDatums;
import cn.edu.hfut.dmic.webcollector.model.Page;
import cn.edu.hfut.dmic.webcollector.plugin.berkeley.BreadthCrawler;

public class techcrunchCrawler extends BreadthCrawler{

	public techcrunchCrawler(String crawlPath, boolean autoParse) {
		super(crawlPath, autoParse);
	}

	@Override
	public void visit(Page page, CrawlDatums next) {
		String url = page.getUrl();
		if(page.matchUrl("https://techcrunch.com/.*")){
			String title = page.select("header[class=article-header page-title]>h1").text();
		}
		
	}
	
	public static void main(String[] args){
		techcrunchCrawler crawler = new techcrunchCrawler("crawl",true);
		crawler.addSeed("https://techcrunch.com/");
		crawler.addRegex("https://techcrunch.com/.*");
		crawler.addRegex("-.*\\.(jpg|png|gif).*");
		crawler.addRegex("-.*#.*");
	}

}
