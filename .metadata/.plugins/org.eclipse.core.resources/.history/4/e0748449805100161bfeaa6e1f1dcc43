package webcollector;

import cn.edu.hfut.dmic.webcollector.model.CrawlDatums;
import cn.edu.hfut.dmic.webcollector.model.Page;
import cn.edu.hfut.dmic.webcollector.plugin.berkeley.BreadthCrawler;

public class crawlerOnePage extends BreadthCrawler{
	
	
	public crawlerOnePage(String crawlPath, boolean autoParse) {
		super(crawlPath, autoParse);
	}

	@Override
	public void visit(Page page, CrawlDatums next) {
		Document doc = page.getDoc();
	}
	
	public static void onePage(String url) throws Exception{
		adafruitCrawler crawler = new adafruitCrawler("crawler", true);
		crawler.addSeed(url);
		crawler.setThreads(1);
	    crawler.setTopN(1);
	    crawler.start(1);
	}

	
}
